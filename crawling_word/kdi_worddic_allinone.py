import argparse
import csv
import json
import re
import time
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait


URL = "https://eiec.kdi.re.kr/material/wordDic.do"

TAB_SECTIONS = {
    "KOR": [""] + list("ã„±ã„´ã„·ã„¹ã…ã…‚ã……ã…‡ã…ˆã…Šã…‹ã…Œã…ã…"),
    "ENG": [""] + list("ABCDEFGHIJKLMNOPQRSTUVWXYZ"),
    "NUM": [""] + [str(i) for i in range(10)],
}


@dataclass
class TermRef:
    term_id: str
    tab: str
    section: str
    label: str


# -------------------------
# Driver + Cert bypass
# -------------------------
def build_driver(headless: bool) -> webdriver.Chrome:
    opts = Options()
    if headless:
        opts.add_argument("--headless=new")
    opts.add_argument("--window-size=1400,900")
    opts.add_argument("--disable-gpu")
    opts.add_argument("--no-sandbox")
    opts.add_argument("--disable-dev-shm-usage")

    # âœ… ì¸ì¦ì„œ ê²½ê³  ë¬´ì‹œ(í¬ë¡¬/ì…€ë ˆë‹ˆì›€)
    opts.add_argument("--ignore-certificate-errors")
    opts.add_argument("--ignore-ssl-errors=yes")
    opts.add_argument("--allow-insecure-localhost")
    opts.set_capability("acceptInsecureCerts", True)

    return webdriver.Chrome(options=opts)


def now_ts() -> str:
    return datetime.now().strftime("%Y%m%d_%H%M%S")


def bypass_cert_warning_if_any(driver: webdriver.Chrome, timeout: int = 8) -> None:
    """
    Chrome 'ê°œì¸ ì •ë³´ ë³´í˜¸ ì˜¤ë¥˜' í™”ë©´ì´ë©´ ìë™ìœ¼ë¡œ í†µê³¼ ì‹œë„.
    - í¬ë¡¬ ê²½ê³  í˜ì´ì§€ bodyì— 'thisisunsafe' íƒ€ì´í•‘ (ë²„íŠ¼ í´ë¦­ë³´ë‹¤ ì•ˆì •ì )
    """
    end = time.time() + timeout
    while time.time() < end:
        title = (driver.title or "")
        url = (driver.current_url or "")

        is_warn = ("ê°œì¸ ì •ë³´ ë³´í˜¸ ì˜¤ë¥˜" in title) or ("chrome-error://" in url)
        if not is_warn:
            # page_sourceì— ERR_CERTê°€ ìˆìœ¼ë©´ ê²½ê³ ì¼ ê°€ëŠ¥ì„±
            try:
                if "ERR_CERT" in driver.page_source or "NET::ERR_CERT" in driver.page_source:
                    is_warn = True
            except Exception:
                pass

        if is_warn:
            try:
                body = driver.find_element(By.TAG_NAME, "body")
                body.send_keys("thisisunsafe")
                time.sleep(1.0)
                return
            except Exception:
                time.sleep(0.5)
                continue
        else:
            return


def wait_js_ready(driver: webdriver.Chrome, timeout: int = 30) -> None:
    WebDriverWait(driver, timeout).until(
        lambda d: d.execute_script("return document.readyState") == "complete"
    )
    WebDriverWait(driver, timeout).until(
        lambda d: d.execute_script(
            "return (typeof langTab === 'function') && (typeof langset === 'function') && (typeof getdetail === 'function');"
        )
    )
    WebDriverWait(driver, timeout).until(
        lambda d: d.execute_script("return document.querySelector('#dictionarySecl') !== null;")
    )
    WebDriverWait(driver, timeout).until(
        lambda d: d.execute_script("return document.querySelector('#dicDetail') !== null;")
    )


# -------------------------
# Tab/Section/List
# -------------------------
def set_tab(driver: webdriver.Chrome, tab: str) -> None:
    driver.execute_script(f"langTab('{tab}');")


def set_section(driver: webdriver.Chrome, tab: str, section: str) -> None:
    driver.execute_script(f"langset('{tab}','{section}');")


def collect_term_refs(driver: webdriver.Chrome, pause: float = 0.25) -> List[TermRef]:
    """
    1) íƒ­/ì„¹ì…˜ì„ ëŒë©´ì„œ ëª©ë¡ a[onclick*='getdetail'] ìŠ¤ìº” â†’ term_id ìˆ˜ì§‘
    2) ì¤‘ë³µ term_idëŠ” 1ê°œë§Œ ìœ ì§€
    """
    refs: Dict[str, TermRef] = {}

    for tab, sections in TAB_SECTIONS.items():
        print(f"\n[LIST] íƒ­ ì „í™˜: {tab}")
        set_tab(driver, tab)
        time.sleep(pause)

        for sec in sections:
            set_section(driver, tab, sec)
            time.sleep(pause)

            anchors = driver.find_elements(By.CSS_SELECTOR, "#dictionarySecl a[onclick*='getdetail']")
            if not anchors:
                continue

            for a in anchors:
                onclick = a.get_attribute("onclick") or ""
                if "getdetail" not in onclick or "'" not in onclick:
                    continue
                try:
                    term_id = onclick.split("'")[1]
                except Exception:
                    continue

                label = (a.text or "").strip()

                if term_id and (term_id not in refs):
                    refs[term_id] = TermRef(term_id=term_id, tab=tab, section=sec, label=label)

    return list(refs.values())


# -------------------------
# Detail + STRICT Integrity
# -------------------------
EMAIL_RE = re.compile(r"[\w\.-]+@[\w\.-]+")


def get_detail_texts(driver: webdriver.Chrome) -> Tuple[str, str]:
    dt = driver.execute_script("return document.querySelector('#dicDetail dt')?.innerText || ''") or ""
    dd = driver.execute_script("return document.querySelector('#dicDetail dd')?.innerText || ''") or ""
    return dt.strip(), dd.strip()


def open_detail_via_js(driver: webdriver.Chrome, tab: str, term_id: str) -> None:
    driver.execute_script(f"langTab('{tab}');")
    driver.execute_script(f"getdetail(null,'{term_id}');")


def _norm(s: str) -> str:
    s = (s or "").strip().lower()
    s = re.sub(r"\s+", "", s)
    s = re.sub(r"[()ï¼ˆï¼‰\[\]{}<>]", "", s)
    s = re.sub(r"[^0-9a-zê°€-í£]", "", s)
    return s


def is_keyword_match(expected_label: str, dt: str) -> bool:
    """
    label(ëª©ë¡ í…ìŠ¤íŠ¸)ê³¼ dt(ìƒì„¸ ì œëª©)ê°€ ì •í•©í•œì§€ íŒë‹¨.
    - ì •ê·œí™” ë¬¸ìì—´ ê¸°ì¤€ í¬í•¨ê´€ê³„/ì•ë¶€ë¶„ í† í° ë¹„êµ
    """
    a = _norm(expected_label)
    b = _norm(dt)
    if not a or not b:
        return False
    if a in b or b in a:
        return True
    if len(a) >= 6 and len(b) >= 6:
        return a[:6] == b[:6]
    return a[:3] == b[:3]


def wait_detail_strict(
    driver: webdriver.Chrome,
    expected_label: str,
    prev_sig: str,
    timeout: int,
    min_content_len: int,
) -> Tuple[str, str, str]:
    """
    âœ… ì €ì¥ ì§ì „ 'ì ˆëŒ€ ë¶ˆì¼ì¹˜ ë°©ì§€' ì¡°ê±´:
    1) dt ë¹„ì–´ìˆì§€ ì•ŠìŒ
    2) ddê°€ ìµœì†Œ ê¸¸ì´ ì´ìƒ
    3) dtê°€ expected_labelê³¼ ë§¤ì¹­
    4) ì´ì „ signatureì™€ ë‹¬ë¼ì„œ ì‹¤ì œ ê°±ì‹  í™•ì¸
    """
    def ready(d) -> bool:
        dt, dd = get_detail_texts(d)
        if not dt:
            return False
        if len(dd) < min_content_len:
            return False
        if not is_keyword_match(expected_label, dt):
            return False
        sig = f"{_norm(dt)}||{_norm(dd)[:120]}"
        return sig != prev_sig

    WebDriverWait(driver, timeout).until(ready)
    dt, dd = get_detail_texts(driver)
    sig = f"{_norm(dt)}||{_norm(dd)[:120]}"
    return dt, dd, sig


# -------------------------
# Checkpoint / Save
# -------------------------
def load_checkpoint(path: Path) -> Dict[str, dict]:
    if not path.exists():
        return {}
    try:
        data = json.loads(path.read_text(encoding="utf-8"))
        out = {}
        for row in data:
            tid = row.get("term_id")
            if tid:
                out[tid] = row
        return out
    except Exception:
        return {}


def save_checkpoint(rows_by_id: Dict[str, dict], path: Path) -> None:
    rows = list(rows_by_id.values())
    path.write_text(json.dumps(rows, ensure_ascii=False, indent=2), encoding="utf-8")


def save_final(rows: List[dict], outdir: Path, prefix: str) -> Tuple[Path, Path]:
    outdir.mkdir(parents=True, exist_ok=True)
    ts = now_ts()

    json_path = outdir / f"{prefix}_{ts}.json"
    csv_path = outdir / f"{prefix}_{ts}.csv"

    json_path.write_text(json.dumps(rows, ensure_ascii=False, indent=2), encoding="utf-8")

    fieldnames = ["term_id", "keyword", "content", "tab", "section", "source", "scraped_at"]
    with csv_path.open("w", encoding="utf-8-sig", newline="") as f:
        w = csv.DictWriter(f, fieldnames=fieldnames)
        w.writeheader()
        for r in rows:
            w.writerow({k: r.get(k, "") for k in fieldnames})

    return json_path, csv_path


# -------------------------
# Debug dump
# -------------------------
def dump_debug(driver: webdriver.Chrome, outdir: Path, term_id: str, tag: str) -> None:
    outdir.mkdir(parents=True, exist_ok=True)
    ts = now_ts()

    html_path = outdir / f"debug_{term_id}_{tag}_{ts}.html"
    png_path = outdir / f"debug_{term_id}_{tag}_{ts}.png"

    try:
        html_path.write_text(driver.page_source, encoding="utf-8", errors="ignore")
    except Exception:
        pass

    try:
        driver.save_screenshot(str(png_path))
    except Exception:
        pass


# -------------------------
# Crawl loop (STRICT)
# -------------------------
def crawl_all_strict(
    driver: webdriver.Chrome,
    refs: List[TermRef],
    outdir: Path,
    limit: Optional[int],
    delay: float,
    timeout: int,
    retries: int,
    checkpoint_every: int,
    min_content_len: int,
    stuck_repeat_threshold: int,
) -> Tuple[List[dict], List[dict]]:
    outdir.mkdir(parents=True, exist_ok=True)
    checkpoint_path = outdir / "checkpoint.json"
    failures_path = outdir / "failures.json"
    debug_dir = outdir / "debug"

    rows_by_id = load_checkpoint(checkpoint_path)
    already = set(rows_by_id.keys())

    if already:
        print(f"[RESUME] ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ: {len(already)}ê±´ ì´ë¯¸ ìˆ˜ì§‘ë¨ â†’ ì´ì–´ì„œ ì§„í–‰")

    failures: List[dict] = []
    prev_sig = ""
    last_dt_norm = ""
    same_dt_count = 0

    total = len(refs) if limit is None else min(limit, len(refs))
    print(f"[CRAWL] ëŒ€ìƒ: {total}ê±´ (ì „ì²´ {len(refs)} ì¤‘)")

    done_count = 0
    for idx, ref in enumerate(refs[:total], start=1):
        if ref.term_id in already:
            if idx % 200 == 0:
                print(f"[SKIP] {idx}/{total} (ì´ë¯¸ ìˆ˜ì§‘ë¨) term_id={ref.term_id}")
            continue

        print(f"\n[{idx}/{total}] term_id={ref.term_id} tab={ref.tab} sec={ref.section} label='{ref.label}'")

        ok = False
        last_err = ""
        for attempt in range(1, retries + 1):
            try:
                print(f"  - ì‹œë„ {attempt}/{retries}: getdetail + STRICT wait(ë¼ë²¨ ë§¤ì¹­)")
                open_detail_via_js(driver, ref.tab, ref.term_id)

                dt, dd, sig = wait_detail_strict(
                    driver=driver,
                    expected_label=ref.label,
                    prev_sig=prev_sig,
                    timeout=timeout,
                    min_content_len=min_content_len,
                )

                # stuck ê°ì§€: dtê°€ ë„ˆë¬´ ì˜¤ë˜ ë™ì¼í•˜ê²Œ ë°˜ë³µë˜ë©´ refresh
                dt_norm = _norm(dt)
                if dt_norm == last_dt_norm:
                    same_dt_count += 1
                else:
                    same_dt_count = 0
                    last_dt_norm = dt_norm

                if same_dt_count >= stuck_repeat_threshold:
                    print(f"  âš ï¸ STUCK ê°ì§€(dt ë°˜ë³µ {same_dt_count}) â†’ refresh í›„ ì¬ì‹œë„")
                    dump_debug(driver, debug_dir, ref.term_id, "stuck_before_refresh")
                    driver.refresh()
                    bypass_cert_warning_if_any(driver)
                    wait_js_ready(driver, timeout=timeout)
                    prev_sig = ""
                    same_dt_count = 0
                    time.sleep(max(0.8, delay))
                    continue

                # âœ… ìµœì¢… ì •í•©ì„± ì¬í™•ì¸(ì´ì¤‘ ì•ˆì „ì¥ì¹˜)
                if not is_keyword_match(ref.label, dt):
                    dump_debug(driver, debug_dir, ref.term_id, "mismatch_after_wait")
                    raise RuntimeError(f"IntegrityFail: label='{ref.label}' dt='{dt}'")

                prev_sig = sig

                row = {
                    "term_id": ref.term_id,
                    "keyword": dt,
                    "content": dd,
                    "tab": ref.tab,
                    "section": ref.section,
                    "source": URL,
                    "scraped_at": datetime.now().isoformat(timespec="seconds"),
                }
                rows_by_id[ref.term_id] = row
                already.add(ref.term_id)

                print(f"  âœ… ì €ì¥: keyword='{dt}' (content {len(dd)} chars) / label match OK")
                ok = True
                done_count += 1
                break

            except Exception as e:
                last_err = repr(e)
                print(f"  âš ï¸ ì‹¤íŒ¨: {last_err}")

                # mismatchë©´ ë””ë²„ê·¸ ë¤í”„
                try:
                    dt_now, dd_now = get_detail_texts(driver)
                    if dt_now and not is_keyword_match(ref.label, dt_now):
                        dump_debug(driver, debug_dir, ref.term_id, "mismatch")
                        print(f"  ğŸ§¾ mismatch ë¤í”„ ì €ì¥: label='{ref.label}' dt='{dt_now}'")
                except Exception:
                    pass

                time.sleep(min(2.0, delay) * attempt)

        if not ok:
            dump_debug(driver, debug_dir, ref.term_id, "final_fail")
            failures.append({
                "term_id": ref.term_id,
                "tab": ref.tab,
                "section": ref.section,
                "label": ref.label,
                "error": last_err,
                "at": datetime.now().isoformat(timespec="seconds"),
            })
            failures_path.write_text(json.dumps(failures, ensure_ascii=False, indent=2), encoding="utf-8")
            print("  âŒ ìµœì¢… ì‹¤íŒ¨ ì²˜ë¦¬(ìŠ¤í‚µ) â†’ failures.json ê¸°ë¡ + debug ì €ì¥")

        if (done_count > 0) and (done_count % checkpoint_every == 0):
            print(f"\n[CHECKPOINT] {done_count}ê±´ë§ˆë‹¤ ì €ì¥ â†’ {checkpoint_path}")
            save_checkpoint(rows_by_id, checkpoint_path)

        time.sleep(delay)

    print(f"\n[CHECKPOINT] ìµœì¢… ì €ì¥ â†’ {checkpoint_path}")
    save_checkpoint(rows_by_id, checkpoint_path)

    return list(rows_by_id.values()), failures


# -------------------------
# Main
# -------------------------
def main():
    p = argparse.ArgumentParser()
    p.add_argument("--outdir", default="out_worddic_strict", help="ì €ì¥ í´ë”(ìƒˆ í´ë” ì¶”ì²œ)")
    p.add_argument("--headless", action="store_true", help="ë¸Œë¼ìš°ì € ì°½ ì—†ì´ ì‹¤í–‰")
    p.add_argument("--limit", type=int, default=0, help="0ì´ë©´ ì „ì²´, ì•„ë‹ˆë©´ ìƒìœ„ Nê°œë§Œ")
    p.add_argument("--delay", type=float, default=0.45, help="ìš”ì²­ ê°„ ë”œë ˆì´(ì´ˆ)")
    p.add_argument("--timeout", type=int, default=80, help="ìƒì„¸ ë¡œë”© ëŒ€ê¸° íƒ€ì„ì•„ì›ƒ(ì´ˆ)")
    p.add_argument("--retries", type=int, default=5, help="í•­ëª©ë‹¹ ì¬ì‹œë„ íšŸìˆ˜")
    p.add_argument("--checkpoint-every", type=int, default=50, help="Nê±´ë§ˆë‹¤ ì²´í¬í¬ì¸íŠ¸ ì €ì¥")
    p.add_argument("--min-content-len", type=int, default=30, help="ë³¸ë¬¸ ìµœì†Œ ê¸¸ì´")
    p.add_argument("--stuck-repeat-threshold", type=int, default=8, help="ê°™ì€ dt ë°˜ë³µ NíšŒë©´ refresh")
    args = p.parse_args()

    outdir = Path(args.outdir)
    limit = None if args.limit == 0 else args.limit

    driver = build_driver(headless=args.headless)
    try:
        driver.get(URL)
        bypass_cert_warning_if_any(driver)  # âœ… ì¸ì¦ì„œ ê²½ê³  ìë™ ìš°íšŒ
        wait_js_ready(driver)

        print("1) ìš©ì–´ ëª©ë¡ ìˆ˜ì§‘ ì¤‘...")
        refs = collect_term_refs(driver)
        print(f"   - ìˆ˜ì§‘ëœ term_id ê°œìˆ˜: {len(refs)}")

        print("\n2) ìƒì„¸ ë‚´ìš© í¬ë¡¤ë§(STRICT) ì¤‘...")
        rows, failures = crawl_all_strict(
            driver,
            refs,
            outdir=outdir,
            limit=limit,
            delay=args.delay,
            timeout=args.timeout,
            retries=args.retries,
            checkpoint_every=args.checkpoint_every,
            min_content_len=args.min_content_len,
            stuck_repeat_threshold=args.stuck_repeat_threshold,
        )

        json_path, csv_path = save_final(rows, outdir=outdir, prefix="kdi_worddic_strict")
        print("\nâœ… ì™„ë£Œ!")
        print(f"- JSON: {json_path.resolve()}")
        print(f"- CSV : {csv_path.resolve()}")
        print(f"- ì‹¤íŒ¨ ê±´ìˆ˜: {len(failures)} (outdir/failures.json + outdir/debug ì°¸ê³ )")

    finally:
        driver.quit()


if __name__ == "__main__":
    main()
